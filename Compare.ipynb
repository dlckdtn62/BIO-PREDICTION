{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrzAzEknCaoakd+WmfKcaq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlckdtn62/BIO-PREDICTION/blob/master/Compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBWIx1veZaGg",
        "colab_type": "code",
        "outputId": "75de4f62-4209-4459-89cb-37a4f76c09b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhgE58uUZkC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/bio'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7fT2_YXZliZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE7tSiK8ZmEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(path+'/test.csv')\n",
        "train = pd.read_csv(path+'/train.csv')\n",
        "submission=pd.read_csv(path + '/sample_submission.csv', index_col='id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iXRN4AgQ35H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dst_filled = train.filter(regex='dst$').T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "tst_dst_filled = test.filter(regex='dst$').T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "\n",
        "train.update(trn_dst_filled)\n",
        "test.update(tst_dst_filled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVWBjUF6xWDR",
        "colab_type": "code",
        "outputId": "765fa62f-41c4-45a6-a832-00107344ac62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "for row in range(len(train)):\n",
        "  start, finish = 37, len(train.columns)-5\n",
        "  for column in range(37, len(train.columns)-4):\n",
        "    if train.iloc[row, column] == 0:\n",
        "      for j in range(column, 36, -1):\n",
        "        if train.iloc[row, j] != 0 and not math.isnan(train.iloc[row, j]):\n",
        "          start = j\n",
        "          break\n",
        "      for j in range(column+1, len(train.columns)-4):\n",
        "        if train.iloc[row, j] != 0 and not math.isnan(train.iloc[row, j]):\n",
        "          finish = j\n",
        "          break\n",
        "      value = (train.iloc[row, start]+train.iloc[row, finish])/(finish-start+1)\n",
        "      for j in range(1, finish-start):\n",
        "        if math.isnan(train.iloc[row, start+j]):\n",
        "          continue\n",
        "        train.iloc[row, start+j] = value*j+train.iloc[row, start]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbK2M2hNqpd",
        "colab_type": "code",
        "outputId": "f357fd0b-f8fb-471a-f0d4-8e9df6e854fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "for row in range(len(test)):\n",
        "  start, finish = 37, len(test.columns)-1\n",
        "  for column in range(37, len(test.columns)):\n",
        "    if test.iloc[row, column] == 0:\n",
        "      for j in range(column, 36, -1):\n",
        "        if test.iloc[row, j] != 0 and not math.isnan(test.iloc[row, j]):\n",
        "          start = j\n",
        "          break\n",
        "      for j in range(column+1, len(test.columns)):\n",
        "        if test.iloc[row, j] != 0 and not math.isnan(test.iloc[row, j]):\n",
        "          finish = j\n",
        "          break\n",
        "      value = (test.iloc[row, start]+test.iloc[row, finish])/(finish-start+1)\n",
        "      for j in range(1, finish-start):\n",
        "        if math.isnan(test.iloc[row, start+j]):\n",
        "          continue\n",
        "        test.iloc[row, start+j] = value*j+test.iloc[row, start]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l6Xj6mN1l7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9629a5f7-f380-4d4d-a7fd-1cae5f18cd7a"
      },
      "source": [
        "compare_df = pd.DataFrame()\n",
        "for i in range(650, 1000, 10):\n",
        "  compare_df['compare'+'_'+str(i)] = np.log(train[str(i)+'_src']/train[str(i)+'_dst'])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JFMfoJPBmOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_df['rho'] = train['rho']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtIRlGGu9u5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_df = compare_df.replace(math.inf, np.NaN)\n",
        "compare_df = compare_df.replace(-math.inf, np.NaN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ErpGuu_u6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dst_filled = compare_df.T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "compare_df.update(trn_dst_filled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDzgj6Z5A-f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgbm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from lightgbm import LGBMRegressor,  plot_importance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8gxPr9KAXkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_lgbm_model(x_data, y_data, k=5):\n",
        "    models = []\n",
        "\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=10)\n",
        "\n",
        "    for trn_idx, val_idx in kfold.split(x_data):\n",
        "        x_trn, y_trn = x_data[trn_idx], y_data[trn_idx]\n",
        "        x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
        "\n",
        "        trainData = lgbm.Dataset(x_trn, y_trn)\n",
        "        testData = lgbm.Dataset(x_val, y_val)\n",
        "\n",
        "        lgb_param = {\n",
        "            'objective': 'regression', \n",
        "            # 'boosting_type': 'dart',\n",
        "            # 'boosting'  : 'dart',\n",
        "            'n_estimators': 2000,\n",
        "            'drop_rate': 0.8, \n",
        "            'skip_drop': 0.8, \n",
        "            'learning_rate' : 0.03,\n",
        "            'random_state' : 42,\n",
        "            'n_jobs' : -1,\n",
        "            'metric' : 'l1',\n",
        "            'colsample_bytree' : 0.7,\n",
        "            'subsample' : 0.7,\n",
        "            }\n",
        "        model = lgbm.train(lgb_param, train_set=trainData, num_boost_round=3000, \n",
        "                           valid_sets = testData, \n",
        "                           verbose_eval=200,\n",
        "                           early_stopping_rounds=500 # Dart earlystopping 안됨\n",
        "                           )\n",
        "        models.append(model)\n",
        "\n",
        "    return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPVEE-BKB34M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5801e5c2-d7b2-4b25-a104-ddb23b282a26"
      },
      "source": [
        "models = {}\n",
        "\n",
        "for label in ['hhb']:\n",
        "    print(\"train column : \", label)\n",
        "    models[label] = train_lgbm_model(np.array(compare_df), train['hhb'])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train column :  hhb\n",
            "Training until validation scores don't improve for 500 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200]\tvalid_0's l1: 0.901919\n",
            "[400]\tvalid_0's l1: 0.84832\n",
            "[600]\tvalid_0's l1: 0.826388\n",
            "[800]\tvalid_0's l1: 0.814063\n",
            "[1000]\tvalid_0's l1: 0.809291\n",
            "[1200]\tvalid_0's l1: 0.807832\n",
            "[1400]\tvalid_0's l1: 0.805944\n",
            "[1600]\tvalid_0's l1: 0.805326\n",
            "[1800]\tvalid_0's l1: 0.804358\n",
            "[2000]\tvalid_0's l1: 0.80263\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1980]\tvalid_0's l1: 0.802526\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.882646\n",
            "[400]\tvalid_0's l1: 0.845889\n",
            "[600]\tvalid_0's l1: 0.832723\n",
            "[800]\tvalid_0's l1: 0.826219\n",
            "[1000]\tvalid_0's l1: 0.821105\n",
            "[1200]\tvalid_0's l1: 0.817309\n",
            "[1400]\tvalid_0's l1: 0.814444\n",
            "[1600]\tvalid_0's l1: 0.813605\n",
            "[1800]\tvalid_0's l1: 0.81048\n",
            "[2000]\tvalid_0's l1: 0.809187\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1994]\tvalid_0's l1: 0.809113\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.911264\n",
            "[400]\tvalid_0's l1: 0.867654\n",
            "[600]\tvalid_0's l1: 0.849982\n",
            "[800]\tvalid_0's l1: 0.843159\n",
            "[1000]\tvalid_0's l1: 0.837955\n",
            "[1200]\tvalid_0's l1: 0.834747\n",
            "[1400]\tvalid_0's l1: 0.830301\n",
            "[1600]\tvalid_0's l1: 0.828789\n",
            "[1800]\tvalid_0's l1: 0.827655\n",
            "[2000]\tvalid_0's l1: 0.826636\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1968]\tvalid_0's l1: 0.826576\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.897403\n",
            "[400]\tvalid_0's l1: 0.854784\n",
            "[600]\tvalid_0's l1: 0.841472\n",
            "[800]\tvalid_0's l1: 0.833965\n",
            "[1000]\tvalid_0's l1: 0.829617\n",
            "[1200]\tvalid_0's l1: 0.82655\n",
            "[1400]\tvalid_0's l1: 0.823869\n",
            "[1600]\tvalid_0's l1: 0.821574\n",
            "[1800]\tvalid_0's l1: 0.819785\n",
            "[2000]\tvalid_0's l1: 0.818978\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1934]\tvalid_0's l1: 0.818721\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.88062\n",
            "[400]\tvalid_0's l1: 0.830334\n",
            "[600]\tvalid_0's l1: 0.809728\n",
            "[800]\tvalid_0's l1: 0.798591\n",
            "[1000]\tvalid_0's l1: 0.794243\n",
            "[1200]\tvalid_0's l1: 0.790907\n",
            "[1400]\tvalid_0's l1: 0.788322\n",
            "[1600]\tvalid_0's l1: 0.784685\n",
            "[1800]\tvalid_0's l1: 0.783237\n",
            "[2000]\tvalid_0's l1: 0.782454\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1997]\tvalid_0's l1: 0.78236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALPNuqyzA7g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for model in models['hhb']:\n",
        "    preds.append(model.predict(np.array(compare_df)))\n",
        "answer = []\n",
        "for j in range(len(preds[0])):\n",
        "  answer.append(np.mean(np.array(preds)[:, j]))\n",
        "compare_df['hhb'] = answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87prmpAeDaVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f93c43d-5d7d-4927-8944-322d10dd1045"
      },
      "source": [
        "for label in ['hbo2']:\n",
        "    print(\"train column : \", label)\n",
        "    models[label] = train_lgbm_model(np.array(compare_df), train['hbo2'])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train column :  hbo2\n",
            "Training until validation scores don't improve for 500 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200]\tvalid_0's l1: 0.55257\n",
            "[400]\tvalid_0's l1: 0.527515\n",
            "[600]\tvalid_0's l1: 0.518492\n",
            "[800]\tvalid_0's l1: 0.512056\n",
            "[1000]\tvalid_0's l1: 0.508224\n",
            "[1200]\tvalid_0's l1: 0.506159\n",
            "[1400]\tvalid_0's l1: 0.504698\n",
            "[1600]\tvalid_0's l1: 0.504032\n",
            "[1800]\tvalid_0's l1: 0.503286\n",
            "[2000]\tvalid_0's l1: 0.502626\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1998]\tvalid_0's l1: 0.502606\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.566631\n",
            "[400]\tvalid_0's l1: 0.544049\n",
            "[600]\tvalid_0's l1: 0.536172\n",
            "[800]\tvalid_0's l1: 0.531855\n",
            "[1000]\tvalid_0's l1: 0.529827\n",
            "[1200]\tvalid_0's l1: 0.527731\n",
            "[1400]\tvalid_0's l1: 0.526736\n",
            "[1600]\tvalid_0's l1: 0.525983\n",
            "[1800]\tvalid_0's l1: 0.525867\n",
            "[2000]\tvalid_0's l1: 0.525257\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1987]\tvalid_0's l1: 0.525106\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.554165\n",
            "[400]\tvalid_0's l1: 0.534066\n",
            "[600]\tvalid_0's l1: 0.525028\n",
            "[800]\tvalid_0's l1: 0.519645\n",
            "[1000]\tvalid_0's l1: 0.516777\n",
            "[1200]\tvalid_0's l1: 0.515082\n",
            "[1400]\tvalid_0's l1: 0.512792\n",
            "[1600]\tvalid_0's l1: 0.512022\n",
            "[1800]\tvalid_0's l1: 0.511412\n",
            "[2000]\tvalid_0's l1: 0.511116\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1896]\tvalid_0's l1: 0.510921\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.553654\n",
            "[400]\tvalid_0's l1: 0.528742\n",
            "[600]\tvalid_0's l1: 0.51864\n",
            "[800]\tvalid_0's l1: 0.512749\n",
            "[1000]\tvalid_0's l1: 0.508147\n",
            "[1200]\tvalid_0's l1: 0.504897\n",
            "[1400]\tvalid_0's l1: 0.502172\n",
            "[1600]\tvalid_0's l1: 0.500886\n",
            "[1800]\tvalid_0's l1: 0.500184\n",
            "[2000]\tvalid_0's l1: 0.499986\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1992]\tvalid_0's l1: 0.499912\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 0.550167\n",
            "[400]\tvalid_0's l1: 0.528465\n",
            "[600]\tvalid_0's l1: 0.520391\n",
            "[800]\tvalid_0's l1: 0.515622\n",
            "[1000]\tvalid_0's l1: 0.513443\n",
            "[1200]\tvalid_0's l1: 0.511036\n",
            "[1400]\tvalid_0's l1: 0.509258\n",
            "[1600]\tvalid_0's l1: 0.507337\n",
            "[1800]\tvalid_0's l1: 0.50596\n",
            "[2000]\tvalid_0's l1: 0.505588\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1990]\tvalid_0's l1: 0.505553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0iTFChDqfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for model in models['hbo2']:\n",
        "    preds.append(model.predict(np.array(compare_df)))\n",
        "answer = []\n",
        "for j in range(len(preds[0])):\n",
        "  answer.append(np.mean(np.array(preds)[:, j]))\n",
        "compare_df['hbo2'] = answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0_vSbkiEBAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71f88a1a-fa89-48be-8626-f21433fb0651"
      },
      "source": [
        "for label in ['ca']:\n",
        "    print(\"train column : \", label)\n",
        "    models[label] = train_lgbm_model(np.array(compare_df), train['ca'])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train column :  ca\n",
            "Training until validation scores don't improve for 500 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200]\tvalid_0's l1: 1.84596\n",
            "[400]\tvalid_0's l1: 1.73879\n",
            "[600]\tvalid_0's l1: 1.68602\n",
            "[800]\tvalid_0's l1: 1.65534\n",
            "[1000]\tvalid_0's l1: 1.63478\n",
            "[1200]\tvalid_0's l1: 1.61952\n",
            "[1400]\tvalid_0's l1: 1.6107\n",
            "[1600]\tvalid_0's l1: 1.60466\n",
            "[1800]\tvalid_0's l1: 1.5998\n",
            "[2000]\tvalid_0's l1: 1.59546\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1997]\tvalid_0's l1: 1.59542\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.92007\n",
            "[400]\tvalid_0's l1: 1.79015\n",
            "[600]\tvalid_0's l1: 1.72676\n",
            "[800]\tvalid_0's l1: 1.68716\n",
            "[1000]\tvalid_0's l1: 1.66552\n",
            "[1200]\tvalid_0's l1: 1.6518\n",
            "[1400]\tvalid_0's l1: 1.64018\n",
            "[1600]\tvalid_0's l1: 1.633\n",
            "[1800]\tvalid_0's l1: 1.62755\n",
            "[2000]\tvalid_0's l1: 1.62404\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1992]\tvalid_0's l1: 1.62381\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.86175\n",
            "[400]\tvalid_0's l1: 1.74474\n",
            "[600]\tvalid_0's l1: 1.68948\n",
            "[800]\tvalid_0's l1: 1.66112\n",
            "[1000]\tvalid_0's l1: 1.64925\n",
            "[1200]\tvalid_0's l1: 1.6388\n",
            "[1400]\tvalid_0's l1: 1.6333\n",
            "[1600]\tvalid_0's l1: 1.62921\n",
            "[1800]\tvalid_0's l1: 1.6263\n",
            "[2000]\tvalid_0's l1: 1.62224\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1998]\tvalid_0's l1: 1.62216\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.81473\n",
            "[400]\tvalid_0's l1: 1.69523\n",
            "[600]\tvalid_0's l1: 1.6375\n",
            "[800]\tvalid_0's l1: 1.6017\n",
            "[1000]\tvalid_0's l1: 1.57774\n",
            "[1200]\tvalid_0's l1: 1.5598\n",
            "[1400]\tvalid_0's l1: 1.55199\n",
            "[1600]\tvalid_0's l1: 1.54358\n",
            "[1800]\tvalid_0's l1: 1.53956\n",
            "[2000]\tvalid_0's l1: 1.53565\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1997]\tvalid_0's l1: 1.53549\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.7602\n",
            "[400]\tvalid_0's l1: 1.6536\n",
            "[600]\tvalid_0's l1: 1.60157\n",
            "[800]\tvalid_0's l1: 1.57263\n",
            "[1000]\tvalid_0's l1: 1.55424\n",
            "[1200]\tvalid_0's l1: 1.54092\n",
            "[1400]\tvalid_0's l1: 1.53179\n",
            "[1600]\tvalid_0's l1: 1.52791\n",
            "[1800]\tvalid_0's l1: 1.52256\n",
            "[2000]\tvalid_0's l1: 1.51868\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\tvalid_0's l1: 1.51868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaZG5c_uEEd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for model in models['ca']:\n",
        "    preds.append(model.predict(np.array(compare_df)))\n",
        "answer = []\n",
        "for j in range(len(preds[0])):\n",
        "  answer.append(np.mean(np.array(preds)[:, j]))\n",
        "compare_df['ca'] = answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jcrk7OJERe8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "188659c0-c0bd-4d18-9c3c-0c5163534447"
      },
      "source": [
        "for label in ['na']:\n",
        "    print(\"train column : \", label)\n",
        "    models[label] = train_lgbm_model(np.array(compare_df), train['na'])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train column :  na\n",
            "Training until validation scores don't improve for 500 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200]\tvalid_0's l1: 1.29761\n",
            "[400]\tvalid_0's l1: 1.26549\n",
            "[600]\tvalid_0's l1: 1.24707\n",
            "[800]\tvalid_0's l1: 1.2363\n",
            "[1000]\tvalid_0's l1: 1.23154\n",
            "[1200]\tvalid_0's l1: 1.229\n",
            "[1400]\tvalid_0's l1: 1.22698\n",
            "[1600]\tvalid_0's l1: 1.22353\n",
            "[1800]\tvalid_0's l1: 1.22226\n",
            "[2000]\tvalid_0's l1: 1.22189\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1729]\tvalid_0's l1: 1.22162\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.32476\n",
            "[400]\tvalid_0's l1: 1.303\n",
            "[600]\tvalid_0's l1: 1.29312\n",
            "[800]\tvalid_0's l1: 1.28898\n",
            "[1000]\tvalid_0's l1: 1.28701\n",
            "[1200]\tvalid_0's l1: 1.28454\n",
            "[1400]\tvalid_0's l1: 1.28423\n",
            "[1600]\tvalid_0's l1: 1.28483\n",
            "Early stopping, best iteration is:\n",
            "[1240]\tvalid_0's l1: 1.28311\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.2949\n",
            "[400]\tvalid_0's l1: 1.26898\n",
            "[600]\tvalid_0's l1: 1.25657\n",
            "[800]\tvalid_0's l1: 1.24891\n",
            "[1000]\tvalid_0's l1: 1.24517\n",
            "[1200]\tvalid_0's l1: 1.24298\n",
            "[1400]\tvalid_0's l1: 1.24034\n",
            "[1600]\tvalid_0's l1: 1.23889\n",
            "[1800]\tvalid_0's l1: 1.23881\n",
            "[2000]\tvalid_0's l1: 1.23847\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1938]\tvalid_0's l1: 1.2377\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.31898\n",
            "[400]\tvalid_0's l1: 1.2923\n",
            "[600]\tvalid_0's l1: 1.28046\n",
            "[800]\tvalid_0's l1: 1.27591\n",
            "[1000]\tvalid_0's l1: 1.27279\n",
            "[1200]\tvalid_0's l1: 1.27147\n",
            "[1400]\tvalid_0's l1: 1.27044\n",
            "[1600]\tvalid_0's l1: 1.2704\n",
            "[1800]\tvalid_0's l1: 1.27051\n",
            "Early stopping, best iteration is:\n",
            "[1395]\tvalid_0's l1: 1.27001\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[200]\tvalid_0's l1: 1.28682\n",
            "[400]\tvalid_0's l1: 1.25672\n",
            "[600]\tvalid_0's l1: 1.23878\n",
            "[800]\tvalid_0's l1: 1.2312\n",
            "[1000]\tvalid_0's l1: 1.2253\n",
            "[1200]\tvalid_0's l1: 1.22271\n",
            "[1400]\tvalid_0's l1: 1.22095\n",
            "[1600]\tvalid_0's l1: 1.21993\n",
            "[1800]\tvalid_0's l1: 1.21857\n",
            "[2000]\tvalid_0's l1: 1.21847\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1979]\tvalid_0's l1: 1.21811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X35iDgVUElF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for model in models['na']:\n",
        "    preds.append(model.predict(np.array(compare_df)))\n",
        "answer = []\n",
        "for j in range(len(preds[0])):\n",
        "  answer.append(np.mean(np.array(preds)[:, j]))\n",
        "compare_df['na'] = answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd-01fF4EnBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f808e6ee-776a-4449-c0fb-a01b3817cb14"
      },
      "source": [
        "compare_df_2 = pd.DataFrame()\n",
        "for i in range(650, 1000, 10):\n",
        "  compare_df_2['compare'+'_'+str(i)] = np.log(test[str(i)+'_src']/test[str(i)+'_dst'])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00QZ4NW3IUpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_df_2 = compare_df_2.replace(math.inf, np.NaN)\n",
        "compare_df_2 = compare_df_2.replace(-math.inf, np.NaN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNF2AxCHEyx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dst_filled = compare_df_2.T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "compare_df_2.update(trn_dst_filled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B0jwrDyE34x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_df_2['rho'] = test['rho']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftqw5m6UE_c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for label in ['hhb', 'hbo2', 'ca', 'na']:\n",
        "  pred = []\n",
        "  for model in models[label]:\n",
        "    pred.append(model.predict(np.array(compare_df_2)))\n",
        "  answer = []\n",
        "  for j in range(len(pred[0])):\n",
        "    answer.append(np.mean(np.array(pred)[:, j]))\n",
        "  compare_df_2[label] = answer\n",
        "  submission[label] = answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W11wKHitG_At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(path+'/just_compared.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}