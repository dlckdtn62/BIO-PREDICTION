{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRaqeD5iFdGFrbzFU6FJY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlckdtn62/BIO-PREDICTION/blob/master/RFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBWIx1veZaGg",
        "colab_type": "code",
        "outputId": "e896dd82-deb0-422d-bdf6-eb0ec3107013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhgE58uUZkC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/bio'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7fT2_YXZliZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE7tSiK8ZmEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(path+'/test.csv')\n",
        "train = pd.read_csv(path+'/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iXRN4AgQ35H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dst_filled = train.filter(regex='dst$').replace(0, np.NaN).T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "tst_dst_filled = test.filter(regex='dst$').replace(0, np.NaN).T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "\n",
        "train.update(trn_dst_filled)\n",
        "test.update(tst_dst_filled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5qn0hFjQ-em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgbm\n",
        "import xgboost as xgb                       # XGBoost 패키지\n",
        "from sklearn.model_selection import KFold   # K-Fold CV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2MeSc1RLJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_lgbm_model(x_data, y_data, k=5):\n",
        "    models = []\n",
        "\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=10)\n",
        "\n",
        "    for trn_idx, val_idx in kfold.split(x_data):\n",
        "        x_trn, y_trn = x_data[trn_idx], y_data[trn_idx]\n",
        "        x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
        "\n",
        "        trainData = lgbm.Dataset(x_trn, y_trn)\n",
        "        testData = lgbm.Dataset(x_val, y_val)\n",
        "\n",
        "        lgb_param = {\n",
        "            'objective': 'regression', \n",
        "            # 'boosting_type': 'dart',\n",
        "            # 'boosting'  : 'dart',\n",
        "            'n_estimators': 1000,\n",
        "            'drop_rate': 0.8, \n",
        "            'skip_drop': 0.8, \n",
        "            'silent' : False,\n",
        "            'learning_rate' : 0.05,\n",
        "            'max_depth' : 12,\n",
        "            'random_state' : 42,\n",
        "            'n_jobs' : -1,\n",
        "            'metric' : 'l1',\n",
        "            'colsample_bytree' : 0.7,\n",
        "            'subsample' : 0.7,\n",
        "            }\n",
        "        model = lgbm.train(lgb_param, train_set=trainData, num_boost_round=3000, \n",
        "                           valid_sets = testData, \n",
        "                           verbose_eval=100,\n",
        "                           early_stopping_rounds=500 # Dart earlystopping 안됨\n",
        "                           )\n",
        "        models.append(model)\n",
        "    return models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-35sFnsMRN2q",
        "colab_type": "code",
        "outputId": "10fb706b-f7ab-4ebb-d3b4-9b9678dbefde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 각 target column별 model 4개 생성 hhb hhb? na ca\n",
        "models = {}\n",
        "\n",
        "for label in ['hbo2', 'hhb', 'ca', 'na']:\n",
        "    print(\"train column : \", label)\n",
        "    models[label] = train_lgbm_model(np.array(train.drop(columns = ['id', 'hbo2', 'hhb', 'ca', 'na'])), train[label])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train column :  hbo2\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 0.682605\n",
            "[200]\tvalid_0's l1: 0.662222\n",
            "[300]\tvalid_0's l1: 0.651314\n",
            "[400]\tvalid_0's l1: 0.647462\n",
            "[500]\tvalid_0's l1: 0.644175\n",
            "[600]\tvalid_0's l1: 0.642618\n",
            "[700]\tvalid_0's l1: 0.64043\n",
            "[800]\tvalid_0's l1: 0.639889\n",
            "[900]\tvalid_0's l1: 0.639003\n",
            "[1000]\tvalid_0's l1: 0.638887\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[998]\tvalid_0's l1: 0.638817\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 0.668073\n",
            "[200]\tvalid_0's l1: 0.647752\n",
            "[300]\tvalid_0's l1: 0.641397\n",
            "[400]\tvalid_0's l1: 0.635889\n",
            "[500]\tvalid_0's l1: 0.632873\n",
            "[600]\tvalid_0's l1: 0.630502\n",
            "[700]\tvalid_0's l1: 0.629152\n",
            "[800]\tvalid_0's l1: 0.627304\n",
            "[900]\tvalid_0's l1: 0.627725\n",
            "[1000]\tvalid_0's l1: 0.627027\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[985]\tvalid_0's l1: 0.626887\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 0.665112\n",
            "[200]\tvalid_0's l1: 0.646112\n",
            "[300]\tvalid_0's l1: 0.638481\n",
            "[400]\tvalid_0's l1: 0.63485\n",
            "[500]\tvalid_0's l1: 0.631915\n",
            "[600]\tvalid_0's l1: 0.63098\n",
            "[700]\tvalid_0's l1: 0.630507\n",
            "[800]\tvalid_0's l1: 0.629715\n",
            "[900]\tvalid_0's l1: 0.629242\n",
            "[1000]\tvalid_0's l1: 0.628791\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[963]\tvalid_0's l1: 0.628593\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 0.659753\n",
            "[200]\tvalid_0's l1: 0.639019\n",
            "[300]\tvalid_0's l1: 0.632826\n",
            "[400]\tvalid_0's l1: 0.628922\n",
            "[500]\tvalid_0's l1: 0.626646\n",
            "[600]\tvalid_0's l1: 0.623197\n",
            "[700]\tvalid_0's l1: 0.621987\n",
            "[800]\tvalid_0's l1: 0.620411\n",
            "[900]\tvalid_0's l1: 0.619967\n",
            "[1000]\tvalid_0's l1: 0.620297\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[842]\tvalid_0's l1: 0.619757\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 0.652184\n",
            "[200]\tvalid_0's l1: 0.635129\n",
            "[300]\tvalid_0's l1: 0.627208\n",
            "[400]\tvalid_0's l1: 0.623556\n",
            "[500]\tvalid_0's l1: 0.620851\n",
            "[600]\tvalid_0's l1: 0.620857\n",
            "[700]\tvalid_0's l1: 0.618711\n",
            "[800]\tvalid_0's l1: 0.618193\n",
            "[900]\tvalid_0's l1: 0.617993\n",
            "[1000]\tvalid_0's l1: 0.618473\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[863]\tvalid_0's l1: 0.617625\n",
            "train column :  hhb\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.02843\n",
            "[200]\tvalid_0's l1: 0.941813\n",
            "[300]\tvalid_0's l1: 0.908186\n",
            "[400]\tvalid_0's l1: 0.888519\n",
            "[500]\tvalid_0's l1: 0.879694\n",
            "[600]\tvalid_0's l1: 0.874971\n",
            "[700]\tvalid_0's l1: 0.87029\n",
            "[800]\tvalid_0's l1: 0.866393\n",
            "[900]\tvalid_0's l1: 0.864299\n",
            "[1000]\tvalid_0's l1: 0.862626\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[998]\tvalid_0's l1: 0.862513\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.01595\n",
            "[200]\tvalid_0's l1: 0.935247\n",
            "[300]\tvalid_0's l1: 0.905022\n",
            "[400]\tvalid_0's l1: 0.890443\n",
            "[500]\tvalid_0's l1: 0.882364\n",
            "[600]\tvalid_0's l1: 0.877542\n",
            "[700]\tvalid_0's l1: 0.873122\n",
            "[800]\tvalid_0's l1: 0.869271\n",
            "[900]\tvalid_0's l1: 0.867248\n",
            "[1000]\tvalid_0's l1: 0.865697\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 0.865697\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.02769\n",
            "[200]\tvalid_0's l1: 0.945956\n",
            "[300]\tvalid_0's l1: 0.914881\n",
            "[400]\tvalid_0's l1: 0.897241\n",
            "[500]\tvalid_0's l1: 0.886699\n",
            "[600]\tvalid_0's l1: 0.87906\n",
            "[700]\tvalid_0's l1: 0.874488\n",
            "[800]\tvalid_0's l1: 0.871094\n",
            "[900]\tvalid_0's l1: 0.869015\n",
            "[1000]\tvalid_0's l1: 0.867519\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[999]\tvalid_0's l1: 0.867503\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.02168\n",
            "[200]\tvalid_0's l1: 0.942734\n",
            "[300]\tvalid_0's l1: 0.910844\n",
            "[400]\tvalid_0's l1: 0.897071\n",
            "[500]\tvalid_0's l1: 0.888954\n",
            "[600]\tvalid_0's l1: 0.884562\n",
            "[700]\tvalid_0's l1: 0.880147\n",
            "[800]\tvalid_0's l1: 0.877714\n",
            "[900]\tvalid_0's l1: 0.874852\n",
            "[1000]\tvalid_0's l1: 0.874048\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[994]\tvalid_0's l1: 0.874015\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.02507\n",
            "[200]\tvalid_0's l1: 0.937124\n",
            "[300]\tvalid_0's l1: 0.900991\n",
            "[400]\tvalid_0's l1: 0.882918\n",
            "[500]\tvalid_0's l1: 0.874499\n",
            "[600]\tvalid_0's l1: 0.866382\n",
            "[700]\tvalid_0's l1: 0.862099\n",
            "[800]\tvalid_0's l1: 0.859304\n",
            "[900]\tvalid_0's l1: 0.856064\n",
            "[1000]\tvalid_0's l1: 0.852792\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[996]\tvalid_0's l1: 0.85273\n",
            "train column :  ca\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 2.05701\n",
            "[200]\tvalid_0's l1: 2.02338\n",
            "[300]\tvalid_0's l1: 2.00805\n",
            "[400]\tvalid_0's l1: 1.99942\n",
            "[500]\tvalid_0's l1: 1.99059\n",
            "[600]\tvalid_0's l1: 1.98688\n",
            "[700]\tvalid_0's l1: 1.98054\n",
            "[800]\tvalid_0's l1: 1.98115\n",
            "[900]\tvalid_0's l1: 1.98183\n",
            "[1000]\tvalid_0's l1: 1.97875\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[994]\tvalid_0's l1: 1.97848\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 2.16632\n",
            "[200]\tvalid_0's l1: 2.12561\n",
            "[300]\tvalid_0's l1: 2.09857\n",
            "[400]\tvalid_0's l1: 2.08237\n",
            "[500]\tvalid_0's l1: 2.08199\n",
            "[600]\tvalid_0's l1: 2.07327\n",
            "[700]\tvalid_0's l1: 2.07637\n",
            "[800]\tvalid_0's l1: 2.07325\n",
            "[900]\tvalid_0's l1: 2.07292\n",
            "[1000]\tvalid_0's l1: 2.07103\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's l1: 2.07103\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 2.10069\n",
            "[200]\tvalid_0's l1: 2.06871\n",
            "[300]\tvalid_0's l1: 2.04438\n",
            "[400]\tvalid_0's l1: 2.03052\n",
            "[500]\tvalid_0's l1: 2.02283\n",
            "[600]\tvalid_0's l1: 2.01648\n",
            "[700]\tvalid_0's l1: 2.0102\n",
            "[800]\tvalid_0's l1: 2.0125\n",
            "[900]\tvalid_0's l1: 2.01217\n",
            "[1000]\tvalid_0's l1: 2.01093\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[988]\tvalid_0's l1: 2.01006\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 2.04979\n",
            "[200]\tvalid_0's l1: 2.02617\n",
            "[300]\tvalid_0's l1: 2.01414\n",
            "[400]\tvalid_0's l1: 2.00408\n",
            "[500]\tvalid_0's l1: 1.99924\n",
            "[600]\tvalid_0's l1: 1.9982\n",
            "[700]\tvalid_0's l1: 1.99369\n",
            "[800]\tvalid_0's l1: 1.99296\n",
            "[900]\tvalid_0's l1: 1.99242\n",
            "[1000]\tvalid_0's l1: 1.99213\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[946]\tvalid_0's l1: 1.99085\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.97826\n",
            "[200]\tvalid_0's l1: 1.93823\n",
            "[300]\tvalid_0's l1: 1.90812\n",
            "[400]\tvalid_0's l1: 1.89301\n",
            "[500]\tvalid_0's l1: 1.88629\n",
            "[600]\tvalid_0's l1: 1.88026\n",
            "[700]\tvalid_0's l1: 1.8742\n",
            "[800]\tvalid_0's l1: 1.87309\n",
            "[900]\tvalid_0's l1: 1.87085\n",
            "[1000]\tvalid_0's l1: 1.8704\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[954]\tvalid_0's l1: 1.86909\n",
            "train column :  na\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.35927\n",
            "[200]\tvalid_0's l1: 1.33369\n",
            "[300]\tvalid_0's l1: 1.31322\n",
            "[400]\tvalid_0's l1: 1.30102\n",
            "[500]\tvalid_0's l1: 1.29411\n",
            "[600]\tvalid_0's l1: 1.29083\n",
            "[700]\tvalid_0's l1: 1.28777\n",
            "[800]\tvalid_0's l1: 1.28392\n",
            "[900]\tvalid_0's l1: 1.28096\n",
            "[1000]\tvalid_0's l1: 1.28038\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[984]\tvalid_0's l1: 1.28027\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.37384\n",
            "[200]\tvalid_0's l1: 1.34639\n",
            "[300]\tvalid_0's l1: 1.33067\n",
            "[400]\tvalid_0's l1: 1.32122\n",
            "[500]\tvalid_0's l1: 1.31362\n",
            "[600]\tvalid_0's l1: 1.30984\n",
            "[700]\tvalid_0's l1: 1.3095\n",
            "[800]\tvalid_0's l1: 1.30772\n",
            "[900]\tvalid_0's l1: 1.30698\n",
            "[1000]\tvalid_0's l1: 1.30802\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[855]\tvalid_0's l1: 1.30619\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.36107\n",
            "[200]\tvalid_0's l1: 1.33374\n",
            "[300]\tvalid_0's l1: 1.32285\n",
            "[400]\tvalid_0's l1: 1.31287\n",
            "[500]\tvalid_0's l1: 1.30721\n",
            "[600]\tvalid_0's l1: 1.30515\n",
            "[700]\tvalid_0's l1: 1.30507\n",
            "[800]\tvalid_0's l1: 1.30384\n",
            "[900]\tvalid_0's l1: 1.3045\n",
            "[1000]\tvalid_0's l1: 1.30386\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[860]\tvalid_0's l1: 1.30317\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.37946\n",
            "[200]\tvalid_0's l1: 1.35733\n",
            "[300]\tvalid_0's l1: 1.34291\n",
            "[400]\tvalid_0's l1: 1.33545\n",
            "[500]\tvalid_0's l1: 1.33152\n",
            "[600]\tvalid_0's l1: 1.32964\n",
            "[700]\tvalid_0's l1: 1.33068\n",
            "[800]\tvalid_0's l1: 1.32707\n",
            "[900]\tvalid_0's l1: 1.3254\n",
            "[1000]\tvalid_0's l1: 1.32544\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[906]\tvalid_0's l1: 1.32463\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[100]\tvalid_0's l1: 1.34893\n",
            "[200]\tvalid_0's l1: 1.32212\n",
            "[300]\tvalid_0's l1: 1.30865\n",
            "[400]\tvalid_0's l1: 1.29812\n",
            "[500]\tvalid_0's l1: 1.29261\n",
            "[600]\tvalid_0's l1: 1.29018\n",
            "[700]\tvalid_0's l1: 1.28805\n",
            "[800]\tvalid_0's l1: 1.28564\n",
            "[900]\tvalid_0's l1: 1.28485\n",
            "[1000]\tvalid_0's l1: 1.28422\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[974]\tvalid_0's l1: 1.2841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvCESxRvRlvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission = pd.read_csv(path + '/sample_submission.csv')\n",
        "for col in models:\n",
        "    preds = []\n",
        "    for model in models[col]:\n",
        "      preds.append(model.predict(np.array(test.drop(columns = ['id']))))\n",
        "\n",
        "    pred = np.mean(preds, axis=0)\n",
        "\n",
        "    sample_submission[col] = pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-qRzgtcSZrK",
        "colab_type": "code",
        "outputId": "666fdd12-dbe7-4d90-bd60-126c28d680cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ca': <lightgbm.basic.Booster at 0x7fafdd30bd68>,\n",
              " 'hbo2': <lightgbm.basic.Booster at 0x7fafe7931ef0>,\n",
              " 'hhb': <lightgbm.basic.Booster at 0x7fafdd30c780>,\n",
              " 'na': <lightgbm.basic.Booster at 0x7fafdd30c5f8>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdINH69oRqcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.to_csv(path+'/original_interpolate.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVWBjUF6xWDR",
        "colab_type": "code",
        "outputId": "d6b71084-215b-4140-a9db-1ec593d9c7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "for row in range(len(train)):\n",
        "  start, finish = 37, len(train.columns)-5\n",
        "  for column in range(37, len(train.columns)-4):\n",
        "    if train.iloc[row, column] == 0:\n",
        "      for j in range(column, 36, -1):\n",
        "        if train.iloc[row, j] != 0 and not math.isnan(train.iloc[row, j]):\n",
        "          start = j\n",
        "          break\n",
        "      for j in range(column+1, len(train.columns)-4):\n",
        "        if train.iloc[row, j] != 0 and not math.isnan(train.iloc[row, j]):\n",
        "          finish = j\n",
        "          break\n",
        "      value = (train.iloc[row, start]+train.iloc[row, finish])/(finish-start+1)\n",
        "      for j in range(1, finish-start):\n",
        "        if math.isnan(train.iloc[row, start+j]):\n",
        "          continue\n",
        "        train.iloc[row, start+j] = value*j+train.iloc[row, start]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUU-UZDMAr42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dst_filled = train.filter(regex='dst$').T.interpolate(method='linear')[::-1].interpolate(method='linear')[::-1].T\n",
        "train.update(trn_dst_filled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QQ4K5EU5O6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QGAZjdW6OV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJsbIs0P6AK3",
        "colab_type": "code",
        "outputId": "828320b9-47c5-4c06-f7e8-48cd4b75817e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for_lgb = train.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])\n",
        "len(for_lgb.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF8RujdL-vyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb_param = {'objective': 'regression', \n",
        "            'boosting_type': 'dart',\n",
        "            'boosting'  : 'dart',\n",
        "            'n_estimators': 1000,\n",
        "            'drop_rate': 0.8, \n",
        "            'skip_drop': 0.8, \n",
        "            'silent' : False,\n",
        "            'learning_rate' : 0.1,\n",
        "            'max_depth' : 12,\n",
        "            'random_state' : 42,\n",
        "            'n_jobs' : -1,\n",
        "            'metric' : 'l1',\n",
        "            'colsample_bytree' : 0.7,\n",
        "            'subsample' : 0.7,\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w4ZTxqE_Yx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdTHhox6jsp",
        "colab_type": "code",
        "outputId": "314a30ef-3f68-4973-d78f-896572a7feb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        }
      },
      "source": [
        "for label in ['hhb', 'ca', 'na', 'hbo2']:\n",
        "  train_x, test_x = train_test_split(train, test_size = 0.33)\n",
        "  # train_data = lgb.Dataset(np.array(train_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])), train_x[label])\n",
        "  # test_data = lgb.Dataset(np.array(test_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])), test_x[label])\n",
        "  selector = RFE(RandomForestRegressor(), n_features_to_select= 8, step=3, verbose = 1)\n",
        "  x = selector.fit(np.array(train_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])), train_x[label])\n",
        "  print(x.n_features_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 71 features.\n",
            "Fitting estimator with 68 features.\n",
            "Fitting estimator with 65 features.\n",
            "Fitting estimator with 62 features.\n",
            "Fitting estimator with 59 features.\n",
            "Fitting estimator with 56 features.\n",
            "Fitting estimator with 53 features.\n",
            "Fitting estimator with 50 features.\n",
            "Fitting estimator with 47 features.\n",
            "Fitting estimator with 44 features.\n",
            "Fitting estimator with 41 features.\n",
            "Fitting estimator with 38 features.\n",
            "Fitting estimator with 35 features.\n",
            "Fitting estimator with 32 features.\n",
            "Fitting estimator with 29 features.\n",
            "Fitting estimator with 26 features.\n",
            "Fitting estimator with 23 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 17 features.\n",
            "Fitting estimator with 14 features.\n",
            "Fitting estimator with 11 features.\n",
            "8\n",
            "Fitting estimator with 71 features.\n",
            "Fitting estimator with 68 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4af9a2b8660f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# test_data = lgb.Dataset(np.array(test_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])), test_x[label])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hhb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hbo2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC87Ek3LA60I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RandomForestRegressor().fit(x.transform(train_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])), train_x['hhb'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o__Wfz9bOOuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x.transform(test_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABXbbge1Od7V",
        "colab_type": "code",
        "outputId": "a1b44230-1257-4c61-ebc4-0ba86b0951f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "[i for idx, i in enumerate(test_x.drop(columns = ['id', 'hhb', 'ca', 'na', 'hbo2']).columns) if x.support_[idx] == True]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['710_src',\n",
              " '740_src',\n",
              " '810_src',\n",
              " '860_src',\n",
              " '880_src',\n",
              " '910_src',\n",
              " '920_src',\n",
              " '990_src']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}